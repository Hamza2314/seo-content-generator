import os
from dotenv import load_dotenv
import anthropic
import time
import requests
from urllib.parse import urlparse
from generator import get_seo_keywords_for_topic
from prompts_and_texts import REFERENCE_TONE_TEXT, CLIENT_INTRO_EXAMPLE

load_dotenv()
client = anthropic.Anthropic(api_key=os.getenv("CLAUDE_API_KEY"))

# Global variables to store reference data and SEO data
reference_information = None
reference_style = REFERENCE_TONE_TEXT  # Hardcoded reference tone
seo_keywords = []

def get_topic_input():
    """Get legal topic from user"""
    print("=== Legal SEO Content Generator ===")
    topic = input("Bitte geben Sie das juristische Thema ein: ").strip()
    
    # Ask for separate keyword topic if needed
    print(f"\nThema f√ºr Content: '{topic}'")
    use_different_keyword_topic = input("M√∂chten Sie ein anderes Thema f√ºr Keyword-Recherche verwenden? (j/n): ").strip().lower()
    
    keyword_topic = topic  # Default to same topic
    if use_different_keyword_topic in ['j', 'ja', 'y', 'yes']:
        keyword_topic = input("Keyword-Recherche-Thema (z.B. 'bet√§ubungsmittelstrafrecht' statt '¬ß 29 und ¬ß 29a BTMG'): ").strip()
        print(f"Keyword-Thema: '{keyword_topic}'")
    
    return topic, keyword_topic

def ask_for_reference_inputs():
    """Ask for optional reference information input"""
    print("\n--- Referenz-Information (f√ºr Analyse) ---")
    use_ref_info = input("M√∂chten Sie eine Quelle f√ºr relevante Rechtsinformationen angeben? (j/n): ").strip().lower()
    ref_info_source = None
    if use_ref_info in ['j', 'ja', 'y', 'yes']:
        ref_info_source = input("URL oder Dateipfad f√ºr Rechtsinformationen: ").strip()
    
    return ref_info_source

def fetch_reference_information(source):
    """Fetch reference information from URL or file path"""
    try:
        # Check if it's a URL
        parsed = urlparse(source)
        if parsed.scheme in ['http', 'https']:
            print("Lade Referenz-Information von URL...")
            response = requests.get(source, timeout=10)
            response.raise_for_status()
            return response.text
        else:
            # Treat as file path
            print("Lade Referenz-Information aus Datei...")
            with open(source, 'r', encoding='utf-8') as file:
                return file.read()
    except Exception as e:
        print(f"Fehler beim Laden der Referenz-Information: {e}")
        return None

def analyze_reference_information(content, topic):
    """Analyze content to extract only relevant legal information for a specific topic"""
    if not content:
        return None
    
    print("Analysiere Referenz-Information...")
    
    prompt = f"""
Du sollst aus folgendem Text AUSSCHLIESSLICH relevante Rechtsinformationen zum Thema "{topic}" extrahieren:

EXTRAHIERE NUR (relevant f√ºr "{topic}"):
- Relevante Paragraphen und Gesetze (¬ß¬ß)
- Wichtige rechtliche Definitionen
- Schl√ºsselinformationen zum Rechtsgebiet
- Verfahrensschritte oder rechtliche Prozesse
- Relevante Strafen oder Rechtsfolgen

IGNORIERE:
- Technische Website-Details
- HTML-Code oder Meta-Informationen
- Irrelevante Werbetexte
- Formatierungen oder Design-Elemente
- Informationen, die nichts mit "{topic}" zu tun haben

Quelle:
{content[:4000]}...

Gib NUR die relevanten Rechtsinformationen zur√ºck, die f√ºr das Schreiben von Rechtstexten zum Thema "{topic}" n√ºtzlich sind.
"""
    
    try:
        response = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=2000,
            temperature=0.2,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.content[0].text.strip()
    except Exception as e:
        print(f"Fehler bei der Informationsanalyse: {e}")
        return None

def generate_outline(topic):
    """Generate comprehensive outline focused purely on legal content - NO SEO keywords"""
    base_prompt = f"""
Du bist ein erfahrener Anwalt und SEO-Experte. Erstelle eine vollst√§ndige Gliederung mit H1- und H2-√úberschriften zu dem Thema "{topic}".

Die Gliederung muss alle relevanten juristischen Aspekte enthalten, die ein Mandant wissen muss oder wonach er suchen k√∂nnte.
Was w√ºrde ein Betroffener alles wissen wollen? Welche Fragen stellen Mandanten? 

Die Gliederung soll NUR das juristische Thema behandeln. KEINE Abschnitte √ºber Kontakt/√úber uns...

Fokus ausschlie√ülich auf rechtliche Inhalte zum Thema "{topic}".

Formatiere die Gliederung so:
- Verwende # f√ºr H1 √úberschriften (Hauptthemen)  
- Verwende ## f√ºr H2 √úberschriften (Unterthemen)

Beispiel:
# Hauptthema 1
## Unterthema 1.1
## Unterthema 1.2
# Hauptthema 2
## Unterthema 2.1
"""
    
    response = client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=2500,
        temperature=0.4,
        messages=[{"role": "user", "content": base_prompt}]
    )
    return response.content[0].text.strip()

def generate_complete_content(topic, outline, target_length=None):
    """Generate complete informational content - NO SEO integration here"""
    
    base_prompt = f"""
Du bist ein professioneller SEO- und Rechtstext-Autor, spezialisiert auf Strafrecht. 
Schreibe einen informativen, √ºberzeugenden Text zu dem Thema "{topic}".

Verwende folgende Gliederung:
{outline}
"""
    
    # Only add length instruction if user specified one
    if target_length:
        length_guides = {
            "short": "L√ÑNGE: Maximal 1500-2000 W√∂rter. Konzentriere dich auf das Wesentliche.",
            "medium": "L√ÑNGE: Etwa 2500-3500 W√∂rter. Ausgewogene Tiefe und √úbersichtlichkeit.",
            "long": "L√ÑNGE: Etwa 4000-5000 W√∂rter. Umfassende und detaillierte Behandlung."
        }
        base_prompt += f"\n{length_guides.get(target_length, '')}\n"
    
    base_prompt += f"""
Anforderungen:
- Juristisch korrekt und vollst√§ndig
- Alle relevanten Paragraphen und Gesetze nennen
- Strafen und Rechtsfolgen aufzeigen
- F√ºr Laien und Mandanten verst√§ndlich aber fachlich fundiert
- Betone Komplexit√§t und Risiken, um Wert anwaltlicher Hilfe zu verdeutlichen
- Informiere Betroffene und zeige den Wert professioneller Verteidigung

FOKUS & RELEVANZ:
- Bleibe STRENG beim Thema "{topic}" - keine allgemeinen Rechtsbelehrungen
- Vermeide generische Verteidigungsstrategien, die f√ºr jedes Delikt gelten
- Keine Abschnitte √ºber allgemeine Rechtfertigungsgr√ºnde (Notwehr, Notstand) - diese geh√∂ren auf eigene Seiten
- KEIN generischer "Anwalt-Bot-Content" - alles muss spezifisch f√ºr "{topic}" sein
- Google-Bot-Optimierung: Jeder Absatz muss direkt mit "{topic}" zu tun haben

Stil: Sachlich, fachkompetent, ultra ansprechend. 
Verwende gelegentlich "wir"-Formulierungen (z.B. "Wir helfen Ihnen", "Gemeinsam entwickeln wir Ihre Verteidigung").
Vermeide akademische Ausschweifungen und Redundanz.
"""

    global reference_information, reference_style
    
    if reference_information:
        base_prompt += f"""
Ber√ºcksichtige diese relevanten Rechtsinformationen, aber beschr√§nke dich nicht darauf:
{reference_information}
"""

    # Client intro instruction
    base_prompt += f"""
EINLEITUNG: Beginne den Artikel mit einer empathischen Mandanten-Einleitung nach diesem Muster (als INSPIRATION, nicht zum Kopieren):
{CLIENT_INTRO_EXAMPLE}
Schreibe eine √§hnliche Einleitung f√ºr das Thema "{topic}". Passe alle Details an (Delikt, Paragraphen, spezifische Situation), variiere die Formulierungen und Struktur.
"""

    # Reference style is always available (hardcoded)
    base_prompt += f"""
TONALIT√ÑT: Orientiere dich am Ton und Schreibstil des folgenden Referenztextes. √úbernimm NUR den Ton und Stil, NICHT die rechtlichen Inhalte, weil es um ein anderes Thema da geht.
REFERENZTEXT:
{reference_style}
"""
    
    # Use streaming to show progress
    print("Starte Content-Generierung mit Streaming...")
    try:
        with client.messages.stream(
            model="claude-sonnet-4-20250514",
            max_tokens=15000,
            temperature=0.4,
            messages=[{"role": "user", "content": base_prompt}]
        ) as stream:
            result = ""
            char_count = 0
            for text in stream.text_stream:
                result += text
                char_count += len(text)
                # Print progress every 1000 characters
                if char_count % 1000 == 0:
                    print(f"  ... {char_count} Zeichen generiert")
        
        print(f"‚úÖ Content-Generierung abgeschlossen: {len(result)} Zeichen")
        return result.strip()
        
    except Exception as e:
        print(f"[ERROR] Content generation failed: {e}")
        # Fallback to non-streaming if streaming fails
        response = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=20000,
            temperature=0.4,
            messages=[{"role": "user", "content": base_prompt}]
        )
        return response.content[0].text.strip()
    
def verify_and_fix_legal_content(content, topic):
    """Verify legal accuracy and fix any errors found"""
    
    print("Pr√ºfe rechtliche Korrektheit und behebe Fehler...")
    
    prompt = f"""
Deine Aufgabe: Pr√ºfe diesen rechtlichen Text zum Thema "{topic}" auf Fehler und korrigiere sie DIREKT im Text.

TEXT:
{content}

KRITISCHE PR√úFPUNKTE - FINDE UND KORRIGIERE:

1. PARAGRAPHEN & GESETZE:
   - Falsche Paragraph-Nummern oder Gesetze (z.B. StGB statt BGB)
   - Veraltete oder nicht existierende Paragraphen
   - Falsche Zuordnungen (z.B. ¬ß 249 StGB bei nachtr√§glicher Gewalt - das w√§re ¬ß 252 oder ¬ß 223 ff.)

2. RECHTLICHE DEFINITIONEN:
   - Unvollst√§ndige Definitionen (z.B. "Zueignungsabsicht" ohne "Aneignungsabsicht" und "Enteignungsvorsatz")
   - Fehlende Tatbestandsmerkmale
   - Unpr√§zise oder umgangssprachliche Formulierungen statt juristischer Fachbegriffe

3. VERH√ÑLTNISSE ZWISCHEN DELIKTEN:
   - Falsche Abgrenzungen zwischen √§hnlichen Straftatbest√§nden
   - Unklare oder falsche Konkurrenzverh√§ltnisse (Spezialit√§t, Subsidiarit√§t)
   - Verwechslung von verwandten Delikten

4. STRAFMASSE & RECHTSFOLGEN:
   - Falsche Mindest- oder H√∂chststrafen
   - Fehlende Qualifikationen oder minder schwere F√§lle
   - Falsche Angaben zu Freiheits- oder Geldstrafen

5. TATBESTANDSMERKMALE:
   - Fehlende oder falsch beschriebene objektive Tatbestandsmerkmale
   - Fehlende oder falsch beschriebene subjektive Tatbestandsmerkmale (Vorsatz, Fahrl√§ssigkeit)
   - Unvollst√§ndige Aufz√§hlung relevanter Merkmale

6. IRRELEVANTER ODER ZU ALLGEMEINER INHALT:
   - Entferne Abschnitte, die zu allgemein sind und bei jedem Delikt stehen k√∂nnten
   - Entferne generische Verteidigungsstrategien ohne Bezug zum spezifischen Delikt
   - Entferne Themen, die eine eigene Seite verdienen (z.B. allgemeine Rechtfertigungsgr√ºnde)
   - Streiche Wiederholungen - konsolidiere √§hnliche Informationen

WENN DU UNSICHER BIST:
- Entferne spekulative oder unsichere Aussagen
- Streiche Abschnitte, bei denen du dir nicht sicher bist, ob sie korrekt sind
- Vereinfache komplexe rechtliche Zusammenh√§nge, wenn du Zweifel hast
- Lieber weniger Inhalt als falsche Informationen

WIE DU KORRIGIEREN SOLLST:
- √Ñndere Fehler DIREKT im Text, an der Stelle wo sie stehen
- Ersetze falsches durch richtiges ODER entferne es komplett
- KEINE Kommentare, Fu√ünoten oder Erkl√§rungen hinzuf√ºgen
- Falls keine Fehler vorhanden: Gib den Text unver√§ndert zur√ºck

NICHT √ÑNDERN:
- Stil, Tonalit√§t, Struktur (au√üer bei rechtlichen Fehlern)
- √úberschriften oder Formatierung
- Korrekte rechtliche Inhalte

Gib nur den korrigierten (oder gek√ºrzten) Text zur√ºck, ohne weitere Erkl√§rungen:
"""
    
    try:
        print("Starte rechtliche Pr√ºfung (Streaming)...")
        with client.messages.stream(
            model="claude-sonnet-4-20250514",
            max_tokens=20000,
            temperature=0.2,  # Keep low for accuracy
            messages=[{"role": "user", "content": prompt}]
        ) as stream:
            result = ""
            for text in stream.text_stream:
                result += text
        
        print(f"‚úÖ Rechtliche Pr√ºfung abgeschlossen (L√§nge: {len(result)} Zeichen)")
        return result.strip()
        
    except Exception as e:
        print(f"[ERROR] Verification failed: {e}")
        return content


def rework_complete_content(original_content, topic, keywords):
    """Integrate SEO keywords into legally-correct content"""
    print(f"Starte SEO-Integration mit {len(keywords) if keywords else 0} Keywords...")
    
    if not keywords:
        return original_content
    
    # Add rate limiting delay
    time.sleep(3)
    print(f"Keywords to integrate: {keywords}")
    keywords_text = ", ".join(keywords)
    
    prompt = f"""
Du bist SEO-Experte. Integriere Keywords in diesen KORREKTEN rechtlichen Text.

KEYWORDS: {keywords_text}

WICHTIG - NICHT √ÑNDERN:
- Rechtliche Fakten
- Paragraphen (¬ß¬ß)
- Strafma√üe
- Rechtsfolgen

NUR ERLAUBT:
- Keywords in √úberschriften einbauen
- Keywords nat√ºrlich in Flie√ütext einf√ºgen
- √úberschriftenstruktur mit Markdown verbessern (# f√ºr H1, ## f√ºr H2, ### f√ºr H3)
- Optional: ### Unter√ºberschriften hinzuf√ºgen, wo es die Struktur verbessert
- Redundanzen entfernen

Der rechtliche Inhalt muss identisch bleiben!

TEXT:
{original_content}

√úberarbeiteter Text mit integrierten Keywords:
"""
    
    try:
        with client.messages.stream(
            model="claude-sonnet-4-20250514",
            max_tokens=20000,
            temperature=0.6,
            messages=[{"role": "user", "content": prompt}]
        ) as stream:
            result = ""
            for text in stream.text_stream:
                result += text
        
        print(f"‚úÖ SEO-Integration abgeschlossen (L√§nge: {len(result)} Zeichen)")
        return result.strip()
        
    except Exception as e:
        if "rate_limit" in str(e):
            print("Rate limit erreicht, warte 60 Sekunden...")
            time.sleep(10)
            return rework_complete_content(original_content, topic, keywords)
        else:
            print(f"[ERROR] SEO integration failed: {e}")
            return original_content

def humanize_content(content, topic):
    """Reduce AI detection while maintaining legal accuracy and readability"""
    
    print("Humanisiere Text (reduziere KI-Erkennbarkeit)...")
    
    prompt = f"""
Deine Aufgabe: √úberarbeite diesen Text, um KI-Erkennbarkeit zu reduzieren, OHNE rechtliche Inhalte zu √§ndern.

TEXT:
{content}

TECHNIKEN ZUR HUMANISIERUNG:

1. SATZSTRUKTUR VARIIEREN:
   - Mische kurze (5-10 W√∂rter) und lange S√§tze (20-30 W√∂rter)
   - Vermeide gleichf√∂rmige Satzl√§ngen
   - Nutze gelegentlich Satzfragmente oder Gedankenstriche

2. NAT√úRLICHE √úBERG√ÑNGE:
   - Ersetze steife √úberg√§nge ("Dar√ºber hinaus", "Ferner", "Zudem")
   - Nutze nat√ºrlichere Verbindungen ("Wichtig ist auch...", "Ein weiterer Punkt...")
   - Gelegentlich direkte Fragen an den Leser

3. TONALIT√ÑT VARIIEREN:
   - Wechsel zwischen sachlich-pr√§zise und leicht umgangssprachlich
   - Gelegentlich pers√∂nliche Ansprache verst√§rken
   - Vermeide zu perfekte, "glatte" Formulierungen

4. UNPERFEKTHEIT EINBAUEN:
   - Gelegentliche Einsch√ºbe in Klammern
   - Hin und wieder Gedankenstriche
   - Nat√ºrliche Betonungen

ABSOLUT VERBOTEN ZU √ÑNDERN:
- Paragraphen, Gesetze, Strafma√üe
- Rechtliche Definitionen oder Tatbestandsmerkmale
- Faktische rechtliche Aussagen
- SEO-Keywords (m√ºssen erhalten bleiben)

ZIEL: <30% KI-Erkennung bei gleichbleibender rechtlicher Korrektheit

Gib nur den humanisierten Text zur√ºck:
"""
    
    try:
        with client.messages.stream(
            model="claude-sonnet-4-20250514",
            max_tokens=20000,
            temperature=0.7,  # HIGHER for more variation
            messages=[{"role": "user", "content": prompt}]
        ) as stream:
            result = ""
            for text in stream.text_stream:
                result += text
        
        print(f"‚úÖ Humanisierung abgeschlossen (L√§nge: {len(result)} Zeichen)")
        return result.strip()
        
    except Exception as e:
        print(f"[ERROR] Humanization failed: {e}")
        return content  # Return original if fails

if __name__ == "__main__":
    # Step 1: Topic Input & Reference Inputs
    topic, keyword_topic = get_topic_input()
    
    # Get reference inputs (only info, style is hardcoded)
    ref_info_source = ask_for_reference_inputs()
    
    # Process reference information (for analysis)
    if ref_info_source:
        content = fetch_reference_information(ref_info_source)
        if content:
            info = analyze_reference_information(content)
            if info:
                reference_information = info
                print("‚úÖ Referenz-Information erfolgreich extrahiert!")
                print("\n" + "="*50)
                print("EXTRAHIERTE RECHTSINFORMATIONEN:")
                print(info)
                print("="*50)
            else:
                print("‚ùå Fehler bei der Informationsextraktion.")
        else:
            print("‚ùå Referenz-Information konnte nicht geladen werden.")
    
    print(f"\n‚úÖ Standard-Referenz-Ton aktiv (K√∂rperverletzung-Stil)")
    
    # Step 2: Generate outline
    print("\n== GLIEDERUNG ==")
    outline = generate_outline(topic)
    print(outline)

    # Step 3: Generate complete content
    print(f"\n== ORIGINAL ARTIKEL ==")
    print("Generiere vollst√§ndigen Artikel...")
    complete_content = generate_complete_content(topic, outline)
    print(complete_content[:500] + "..." if len(complete_content) > 500 else complete_content)
    
    # Step 4: Verify and fix legal errors
    print(f"\n== RECHTLICHE PR√úFUNG UND KORREKTUR ==")
    corrected_content = verify_and_fix_legal_content(complete_content, topic)
    print(corrected_content[:500] + "..." if len(corrected_content) > 500 else corrected_content)
    
    # Step 5: SEO Keyword Research
    print(f"\n== SEO KEYWORD RESEARCH (Thema: '{keyword_topic}') ==")
    seo_keywords = get_seo_keywords_for_topic(keyword_topic)
    if seo_keywords:
        print("‚úÖ SEO Keywords erfolgreich generiert:")
        for i, kw in enumerate(seo_keywords, 1):
            print(f"  {i}. {kw}")
    else:
        print("‚ùå Keine Keywords erhalten.")
        print("üí° Tipp: Versuchen Sie ein breiteres Keyword-Thema (z.B. 'bet√§ubungsmittelstrafrecht' statt '¬ß 29 BtMG')")
    
    # Step 6: SEO Integration
    if seo_keywords:
        print(f"\n== SEO-OPTIMIERUNG ==")
        print("Integriere Keywords in korrigierten Text...")
        seo_optimized_content = rework_complete_content(corrected_content, topic, seo_keywords)
        print(seo_optimized_content[:500] + "..." if len(seo_optimized_content) > 500 else seo_optimized_content)
    else:
        print(f"\n== NACH RECHTLICHER KORREKTUR ==")
        seo_optimized_content = corrected_content
        print(corrected_content[:500] + "..." if len(corrected_content) > 500 else corrected_content)
    
    # Step 7: Humanization (NEW!)
    print(f"\n== HUMANISIERUNG ==")
    print("Reduziere KI-Erkennbarkeit...")
    humanized_content = humanize_content(seo_optimized_content, topic)
    
    print("\n== FINALER HUMANISIERTER ARTIKEL ==")
    print(humanized_content)
    
    print("\n" + "="*50)